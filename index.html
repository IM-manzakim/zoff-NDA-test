<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
  <title>Zoff DNA - iPhone PoC</title>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3"></script>
  <style>
    /* モバイル向けにUIを最適化 */
    body { margin: 0; background: #000; color: #fff; font-family: sans-serif; overflow: hidden; }
    #container { position: relative; width: 100vw; height: 100vh; }
    video, canvas { position: absolute; top: 0; left: 0; width: 100%; height: 100%; object-fit: cover; transform: scaleX(-1); }
    #ui-overlay { position: absolute; bottom: 40px; left: 0; width: 100%; text-align: center; z-index: 10; }
    .btn { background: #0070BB; color: #fff; border: none; padding: 15px 40px; border-radius: 30px; font-size: 18px; font-weight: bold; }
    #status { position: absolute; top: 20px; width: 100%; text-align: center; font-size: 14px; background: rgba(0,0,0,0.5); padding: 5px 0; }
  </style>
</head>
<body>
  <div id="container">
    <video id="webcam" autoplay playsinline muted></video>
    <canvas id="output_canvas"></canvas>
    <div id="status">カメラ起動中...</div>
    <div id="ui-overlay">
      <button id="start_btn" class="btn">計測開始</button>
      <div id="result" style="margin-top:20px; font-size: 20px; font-weight: bold;"></div>
    </div>
  </div>

  <script type="module">
    import { FaceLandmarker, FilesetResolver } from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3";

    const video = document.getElementById("webcam");
    const canvasElement = document.getElementById("output_canvas");
    const canvasCtx = canvasElement.getContext("2d");
    const status = document.getElementById("status");
    const startBtn = document.getElementById("start_btn");
    
    let faceLandmarker;
    let lastVideoTime = -1;

    async function setup() {
      const filesetResolver = await FilesetResolver.forVisionTasks("https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3/wasm");
      faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {
        baseOptions: { 
          modelAssetPath: `https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`,
          delegate: "GPU" 
        },
        runningMode: "VIDEO", numFaces: 1, refineLandmarks: true
      });
      status.innerText = "カメラ準備完了";
      startCamera();
    }

    function startCamera() {
      const constraints = { video: { facingMode: "user", width: 1280, height: 720 } };
      navigator.mediaDevices.getUserMedia(constraints).then((stream) => {
        video.srcObject = stream;
        video.addEventListener("loadeddata", predict);
      }).catch(err => {
        status.innerText = "カメラエラー: " + err;
      });
    }

    async function predict() {
      canvasElement.width = video.videoWidth;
      canvasElement.height = video.videoHeight;
      
      if (lastVideoTime !== video.currentTime) {
        lastVideoTime = video.currentTime;
        const results = faceLandmarker.detectForVideo(video, performance.now());
        
        canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);
        if (results.faceLandmarks && results.faceLandmarks.length > 0) {
          status.innerText = "顔認識中: OK";
          // 描画ロジック (簡易点描)
          const pts = results.faceLandmarks[0];
          canvasCtx.fillStyle = "#0070BB";
          pts.forEach((p, i) => { if(i%20===0) canvasCtx.fillRect(p.x * canvasElement.width, p.y * canvasElement.height, 4, 4); });
        } else {
          status.innerText = "顔が見つかりません";
        }
      }
      requestAnimationFrame(predict);
    }
    setup();
  </script>
</body>
</html>
